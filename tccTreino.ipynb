{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import joblib\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar e pré-processar o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Função para aplicar stemming em cada palavra da mensagem\n",
    "def apply_stemming(text):\n",
    "    # Verifica se o valor é string, caso contrário retorna texto vazio\n",
    "    if isinstance(text, str):\n",
    "        words = word_tokenize(text.lower())  # Tokeniza o texto\n",
    "        stemmed_words = [stemmer.stem(word) for word in words]  # Aplica stemming em cada palavra\n",
    "        return ' '.join(stemmed_words)\n",
    "    else:\n",
    "        print(\"erro\")\n",
    "        return ''  # Retorna string vazia se não for texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset\n",
    "df = pd.read_csv('enron_spam_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir valores nulos por strings vazias\n",
    "df['Message'] = df['Message'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar stemming nas mensagens\n",
    "df['Message'] = df['Message'].apply(apply_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar arquivo pós-processamento\n",
    "# df.to_csv('datasetPronto.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar as features e os rótulos\n",
    "X = df['Message']\n",
    "y = df['Spam/Ham'].apply(lambda x: 1 if x == 'spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir o dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar o texto em vetores de TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar o modelo SVM com kernel RBF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o modelo SVM com kernel RBF\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')  # C é o parâmetro de regularização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "svm_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o modelo em um arquivo\n",
    "joblib.dump(svm_model, 'modelo_sem_ajuste_sem_kfold-c1-gSC.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer_sem_ajuste_sem_kfold-c1-gSC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar modelo\n",
    "svm_model = joblib.load('modelo_sem_ajuste_sem_kfold-c1-gSC.pkl')\n",
    "vectorizer = joblib.load('vectorizer_sem_ajuste_sem_kfold-c1-gSC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = svm_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testtxt = \"\"\n",
    "test = apply_stemming(testtxt)\n",
    "testl = vectorizer.transform([test])  # Note a mudança para uma lista\n",
    "y_pred = svm_model.predict(testl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['ham', 'spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto de exibição da matriz de confusão\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['ham', 'spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a matriz de confusão\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar os Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os parâmetros a serem testados\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o GridSearchCV para encontrar os melhores parâmetros\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver os melhores parâmetros\n",
    "print(f\"Melhores parâmetros: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo com os melhores parâmetros\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "best_svm_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o modelo otimizado em um arquivo\n",
    "joblib.dump(best_svm_model, 'modelo_com_ajuste_e_kfold.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer_com_ajuste_e_kfold.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_svm_model = joblib.load('modelo_treinado.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo otimizado\n",
    "y_pred_optimized = best_svm_model.predict(X_test_tfidf)\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred_optimized) * 100:.2f}%\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred_optimized, target_names=['ham', 'spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred_optimized, labels=['ham', 'spam'])# Matriz de "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto de exibição da matriz de confusão\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['ham', 'spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a matriz de confusão\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
